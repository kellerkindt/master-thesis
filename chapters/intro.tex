\chapter{Introduction}

Since the industrial revolution, humans strive for more automation in the industry as well as in the every day life.
What was at first a cost saving measurement in factories, now also is a differentiation method for products.
A new product must prove a higher level comfort to the customer than the previous generation as well as all the competitors.
As such, the ambitions of the industry are focused on increasing the value of their products for the customer.

The automotive industry is one of the prime examples of this.
Never was traveling from one place to another as comfortable as nowadays.
Aspects like an elegant interior design, comfortable seats, air conditioning, entertainment systems and safety measurements need to be considered by car manufacturers to be competitive these days. 
The next luxury enhancement will be the autonomously driving vehicle.
No longer shall the owner of a car steer it, but instead the car becomes his or hers personal chauffeur, driving the optimal route, the most comfortable way and being more reliable and safer than any human ever could.

The reason, autonomously driving cars are not common already, is their big complexity increase.
Compared to already established technologies like parking assistants, entertainment systems or more efficient engine controllers, letting a computer reliably understand a certain traffic situation requires masses of input data and complex algorithms to process.
As such, the problem itself becomes massive and cannot be solved that easily.
To solve this, the industry has no choice than to divide this into many small pieces and work out solutions to it step by step.

The MEC-View research project explorers one such step: whether and how to include external, steady mounted sensors in the decision finding process for partially autonomous vehicles in situations where onboard sensors are insufficient.
%As additional restriction, decisions made by autonomous vehicles  are not allowed to disrupt the surrounding traffic flow otherwise phenomens like the \todo{Phantomstau} could be caused by them.
To not disrupt traffic flow with non-human behavior, one needs to study and thereby watch human traffic.
Automatically analyzing traffic from video footage requires a lot of computation power and can be further optimized by specialized hardware such as GPUs.

This thesis will conceptualize and realize a distributed and automated computer vision pipeline which can be used to analyzes traffic flow within video footage.



\section{MEC-View}

The MECView research project - funded by the Federal Ministry for Economic Affairs and Energy - aims to supplement the field of view of automated driving cars with road-side sensor data using 5G mobile communication. The sensor information is merged into an environment model on the so-called Mobile Edge Computing (MEC) server. This server is directly attached to the radio station to ensure low latency environment model updates.

The project is tested at an intersection in Ulm, Germany.
Currently, there are 15 lidar and video sensors installed.
Those sensors send their detections to the (MEC) server.
A fusion-algorithm merges those detections into one environment model and sends it back to the (MEC) server and to the automated cars.

Additionally, general traffic flow is analyzed to learn about movement patterns.
To do so, 4k video data is captured by an air drone from real world cross roads.
On each frame of such a recording, cars are detected with a neuronal network.
Detected cars are tracked throughout the video to compute the movement speed and position in time of each car.
In an analysis of all vehicles, hot-spots of high and low traffic flow can be determined.

