\chapter{Introduction}

Since the industrial revolution, humans strive for more automation in the industry as well as in the every day life.
What was at first a cost saving measurement in factories, now also is a differentiation method for products.
A new product must prove a higher level comfort to the customer than the previous generation as well as all the competitors.
As such, the ambitions of the industry are focused on increasing the value of their products for the customer.

The automotive industry is one of the prime examples of this.
Never was traveling from one place to another as comfortable as nowadays.
Aspects like an elegant interior design, comfortable seats, air conditioning, entertainment systems and safety measurements need to be considered by car manufacturers to be competitive these days. 
The next luxury enhancement will be the autonomously driving vehicle.
No longer shall the owner of a car steer it, but instead the car becomes his or hers personal chauffeur, driving the optimal route, the most comfortable way and being more reliable and safer than any human ever could.

The reason, autonomously driving cars are not common already, is their big complexity increase.
Compared to already established technologies like parking assistants, entertainment systems or more efficient engine controllers, letting a computer reliably understand a certain traffic situation requires masses of input data and complex algorithms to process.
As such, the problem itself becomes massive and cannot be solved that easily.
So the industry has no choice than to divide this into many small pieces and work out solutions step by step.

The MEC-View research project explorers one such step: whether and how to include external, steady mounted sensors in the decision finding process for partially autonomous vehicles in situations where onboard sensors are insufficient.
%As additional restriction, decisions made by autonomous vehicles  are not allowed to disrupt the surrounding traffic flow otherwise phenomens like the \todo{Phantomstau} could be caused by them.
To not disrupt traffic flow with non-human behavior, one needs to study and thereby watch human traffic.
Automatically analyzing traffic from video footage requires a lot of computation power and can be further optimized by specialized hardware such as GPUs\footnote{Graphics Processing Units}.

This thesis will conceptualize and realize a distributed and automated computer vision pipeline which is in this case used to analyzes traffic flow within video footage.
Compared to an existing but highly manual workflow, the new system shall help to utilize the available hardware more efficiently by reducing idle times.
Stage transitions and basic scheduling shall be automated to allow a user to plan and execute multiple projects ahead of time and in parallel.
%The current, highly manual workflow, can lead to a lot of idle time inbetween user intervention.

%The available hardware resources shall be utilized more efficiently, as well as time that is required by humans to monitor the system.


\newpage
\section{MEC-View}

The MEC-View research project\cite{mecview:main} - funded by the German Federal Ministry for Economic Affairs and Energy - aims to supplement the field of view of automated driving cars with road-side sensor data using 5G mobile communication. The sensor information is merged into an environment model on the so-called Mobile Edge Computing (MEC) server. This server is directly attached to the radio station to ensure low latency environment model updates.

The project is tested at an intersection in Ulm, Germany.
Currently, there are 15 lidar and video sensors installed.
Those sensors send their detections to the (MEC) server.
A fusion-algorithm merges those detections into one environment model and sends it back to the (MEC) server and to the automated cars.

Additionally, general traffic flow is analyzed to learn about movement patterns.
To do so, 4k video data is captured by an air drone from real world cross roads - not limited to the intersection in Ulm.
On each frame of such a recording, cars are detected with a neuronal network.
Detected cars are tracked throughout the video to compute the movement speed and position in time of each car.
In an analysis of all vehicles, hot-spots of high and low traffic flow can be determined.

This thesis conceptualizes and implements a distributed and automated computer vision pipeline to increase the efficiency in video analysis management and execution.
It is of concern for this thesis on how to retrieve the footage or what is further archived with the results of evaluated video footage.
The focus is on utilizing available hardware resources to manage multiple projects simultaneously and to reduce the idle time of relevant hardware by slow human reaction and availability times. \todo{reaction time: like its done but not noticed for another x mins/hours, availability: work hours}

