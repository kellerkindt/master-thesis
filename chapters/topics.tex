\chapter{Outcome and Measurements}

In this chapter the outcome is measured and evaluated.

\todo{compare to initial deliverable requirements?}

\section{What did not work as expected}

\todo{timeout for events might be reached when in between the bandwidth is used by a copy of a large file and the extend signal is because of that deferred, stages that are fine are then marked as failed}

\todo{. old sections}

\section{User Authentication and Security}

One aspect that was not yet mentioned at all is user authentication and security.
Winslow is prepared in this regards because every project has an owner field and a member list and every web access check these.
An internal user repository also associates user with groups and provides defaults, such as the user and group \enquote{anonymous} and \enquote{root}, for no and full access privileges, respectively.
But at the moment, there is no user login, instead to the system all requests seem to be issued by \enquote{root}.
In the future this is planned to be replaced by an Single Sign-On implementation that uses the user accounts of our company.
Winslow is then associating a from this service given user name to an internal user and groups.
Unknown users are not allowed to see or alter anything, known users will be able to create and view their own projects and projects they are listed in as members.
%\todo{mostly planned, implemented not tested}

Winslow also supports secure HTTP (HTTPS) whenever a SSL certificate is provided\footnote{This can be seen in \autoref{appendix:winslow_installation}}.

\begin{comment}
\section{Storage}

One of the central concerns is the storage management.
The program needs to make input files available on each execution node and collect the results once the computation is complete.
There are a few main architectural strategies to approach this.
Simplified, either at a centralized location which is accessed by all execution nodes, a copy of the input files to the execution nodes or decentralized and distributed between all execution nodes and replication.
The advantages and disadvantages can depend on the specific implementation and is therefore discussed in combination of such (see \autoref{state_of_the_art}).

Further testing is required to decide whether a more complex storage system is required, or the simplicity of a centralized solution outweighs the setup and maintenance overhead.

%\subsection{Hadoop File System}
%\cite{hdfs:main}
%\cite{hdfs:doc}
%\todo{redudancy for evenly distributed}

%\subsection{NFS}
%
%local/per node cache?

\section{Coordination}

Another important concern is the coordination of the nodes.
A central coordinator with external server nodes, such as GitLab and Jenkins have, might not be sufficient for more complex and longer lasting pipelines.
The probability that the master would need to be offline while there is a stage executed, is in the scenario of the desired workflow higher than for GitLab or Jenkins, because the stage is being execution for hours or days.
Coupling stage execution plans on node availability ahead of time, as well as recovering from a sudden master failure implies additional implementation complexity.
A decentralized coordination needs to be able to do this as well, but also allows the usage of the system while a node failed or is unreachable due to maintenance.
With further prototyping and research a reasonable solution shall be found.

\section{Binary distribution}

In a time where containers are common and have proven to be usable, the installation of the binaries directly on the operating system they are executed on shall be avoided.
There shall be no manual, nor automatic but custom file copies of the binaries or images from one server to the other.
Experience shows, that without a proper management, this can easily become a mess, in which it is no longer clear, which files or images belong to which version.
At the same time, making all binaries publicly available through the Docker Hub\cite{docker:hub} is no option either.
Whether a self hosted Docker Registry\cite{docker:registry} could be the solution to this will be determined in further testing.

\section{User Interface}

Providing a useful user interface might not be important to the functionality of the system itself but for the user experience.
A bad user experience will cause a system not to be used.
It became common practice for a rich user experience to be web based and interactive with JavaScript.
For a potentially decentralized system, it is also advantageous to be able to access a disconnected node in the same manner as the remaining system, which further encourages a web based solution.
Web based solutions such as React and Angular shall therefore be investigated for being used as user interface.

\section{Requirements}

\todo{more than first defined - as expected}

\todo{lots more UI shortcuts found necessary while starting to use winslow}

\section{Architecture}

\todo{loosely coupled backend driver}\autoref{architecture:detailed}
\end{comment}

\section{High Level System Overview}

\todo{.delete?}

\autoref{architecture:high-level} shows the high level system overview of Winslow as it has been implemented by the end of this thesis.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{architecture.png}
	\caption{High level view on the system structure}
	\label{architecture:high-level}
\end{figure}


\todo{explain what is going on in \autoref{architecture:high-level}}

\section{Failure resilience}

\todo{.delete? or polish!}

One of the initial requirements is to be resilient against node failures.
Node failures can be simulated easily by killing the Docker container of a Winslow instance.
The behaviour that is then displayed, depends on whether that killed instance was executing a stage.
If it did not, the only change is that in the Web-Application the node with its utilization reports will vanish.

But if it did execute a stage, it held locks for it.
These locks will expire, and after the additional grace period (see \autoref{message:grace_period}), the other instances will notice it, lock the affected project themselves and mark the execution as failed.
Currently, the project is then paused and user confirmation awaited.
An alternative to this could be to re-schedule the stage automatically.